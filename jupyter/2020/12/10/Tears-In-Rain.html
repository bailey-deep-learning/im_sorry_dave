<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>All those moments will be los(s)t in time, like tears in rain. | I’m sorry, Dave. I’m afraid I can’t do that.</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="All those moments will be los(s)t in time, like tears in rain." />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I am completely operational, and all my circuits are functioning perfectly." />
<meta property="og:description" content="I am completely operational, and all my circuits are functioning perfectly." />
<link rel="canonical" href="https://bailey-deep-learning.github.io/im_sorry_dave/jupyter/2020/12/10/Tears-In-Rain.html" />
<meta property="og:url" content="https://bailey-deep-learning.github.io/im_sorry_dave/jupyter/2020/12/10/Tears-In-Rain.html" />
<meta property="og:site_name" content="I’m sorry, Dave. I’m afraid I can’t do that." />
<meta property="og:image" content="https://bailey-deep-learning.github.io/im_sorry_dave/images/posts/2020-12-10-Tears-In-Rain/Tears-In-Rain.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-10T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://bailey-deep-learning.github.io/im_sorry_dave/jupyter/2020/12/10/Tears-In-Rain.html","@type":"BlogPosting","headline":"All those moments will be los(s)t in time, like tears in rain.","dateModified":"2020-12-10T00:00:00-06:00","datePublished":"2020-12-10T00:00:00-06:00","image":"https://bailey-deep-learning.github.io/im_sorry_dave/images/posts/2020-12-10-Tears-In-Rain/Tears-In-Rain.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://bailey-deep-learning.github.io/im_sorry_dave/jupyter/2020/12/10/Tears-In-Rain.html"},"description":"I am completely operational, and all my circuits are functioning perfectly.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/im_sorry_dave/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://bailey-deep-learning.github.io/im_sorry_dave/feed.xml" title="I'm sorry, Dave. I'm afraid I can't do that." /><link rel="shortcut icon" type="image/x-icon" href="/im_sorry_dave/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/im_sorry_dave/">I&#39;m sorry, Dave. I&#39;m afraid I can&#39;t do that.</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/im_sorry_dave/about/">About Me</a><a class="page-link" href="/im_sorry_dave/search/">Search</a><a class="page-link" href="/im_sorry_dave/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">All those moments will be los(s)t in time, like tears in rain.</h1><p class="page-description">I am completely operational, and all my circuits are functioning perfectly.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-10T00:00:00-06:00" itemprop="datePublished">
        Dec 10, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      55 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/im_sorry_dave/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/bailey-deep-learning/im_sorry_dave/tree/master/_notebooks/2020-12-10-Tears-In-Rain.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/im_sorry_dave/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/bailey-deep-learning/im_sorry_dave/master?filepath=_notebooks%2F2020-12-10-Tears-In-Rain.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/im_sorry_dave/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/bailey-deep-learning/im_sorry_dave/blob/master/_notebooks/2020-12-10-Tears-In-Rain.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/im_sorry_dave/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Under-the-Hood:-Training-a-Digit-Classifier">Under the Hood: Training a Digit Classifier </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Pixels:-The-Foundations-of-Computer-Vision">Pixels: The Foundations of Computer Vision </a></li>
<li class="toc-entry toc-h2"><a href="#First-Try:-Pixel-Similarity">First Try: Pixel Similarity </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Problem-Statement">Problem Statement </a></li>
<li class="toc-entry toc-h3"><a href="#Process">Process </a></li>
<li class="toc-entry toc-h3"><a href="#L1-and-L2-norm">L1 and L2 norm </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Computing-Metrics-Using-Broadcasting">Computing Metrics Using Broadcasting </a></li>
<li class="toc-entry toc-h2"><a href="#Stochastic-Gradient-Descent-(SGD)">Stochastic Gradient Descent (SGD) </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Calculating-Gradients">Calculating Gradients </a></li>
<li class="toc-entry toc-h3"><a href="#Stepping-With-a-Learning-Rate">Stepping With a Learning Rate </a></li>
<li class="toc-entry toc-h3"><a href="#An-End-to-End-SGD-Example">An End-to-End SGD Example </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Step-1:-Initialize-the-parameters">Step 1: Initialize the parameters </a></li>
<li class="toc-entry toc-h4"><a href="#Step-2:-Calculate-the-predictions">Step 2: Calculate the predictions </a></li>
<li class="toc-entry toc-h4"><a href="#Step-3:-Calculate-the-loss">Step 3: Calculate the loss </a></li>
<li class="toc-entry toc-h4"><a href="#Step-4:-Calculate-the-gradients">Step 4: Calculate the gradients </a></li>
<li class="toc-entry toc-h4"><a href="#Step-5:-Step-the-weights.">Step 5: Step the weights. </a></li>
<li class="toc-entry toc-h4"><a href="#Step-6:-Repeat-the-process">Step 6: Repeat the process </a></li>
<li class="toc-entry toc-h4"><a href="#Step-7:-stop">Step 7: stop </a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#Summarizing-Gradient-Descent">Summarizing Gradient Descent </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#The-MNIST-Loss-Function">The MNIST Loss Function </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Sigmoid">Sigmoid </a></li>
<li class="toc-entry toc-h3"><a href="#SGD-and-Mini-Batches">SGD and Mini-Batches </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Putting-It-All-Together">Putting It All Together </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Creating-an-Optimizer">Creating an Optimizer </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Adding-a-Nonlinearity">Adding a Nonlinearity </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Going-Deeper">Going Deeper </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Jargon-Recap">Jargon Recap </a></li>
<li class="toc-entry toc-h2"><a href="#Questionnaire">Questionnaire </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Further-Research">Further Research </a></li>
</ul>
</li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-12-10-Tears-In-Rain.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Under-the-Hood:-Training-a-Digit-Classifier">
<a class="anchor" href="#Under-the-Hood:-Training-a-Digit-Classifier" aria-hidden="true"><span class="octicon octicon-link"></span></a>Under the Hood: Training a Digit Classifier<a class="anchor-link" href="#Under-the-Hood:-Training-a-Digit-Classifier"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This one is the big one. Now we have made it past the introduction of the course it is time to get under the hood and start implementing some of the functionality for ourselves. I am going to be taking quite thorough notes as I want to make sure I understand everything before I move onto Chapter 5.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So far all the heavy lifting has been done for us, the fastai library is a nice high level API written on top of PyTorch and abstracted in such a way that the "magic" / "obfuscation" is a little hard to determine what is actually happening. So in this chapter we will be making a hand written digit classifier, a simple classifier that can determine whether or not a 28px * 28px image of a hand written digit is either a <strong>3</strong> or a <strong>7</strong>. We will try to figure out a good baseline from which we can assess our model and then proceed to write out each element of the model in simple python, before seeing it all wrapped up in the nice and tidy fastai API.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pixels:-The-Foundations-of-Computer-Vision">
<a class="anchor" href="#Pixels:-The-Foundations-of-Computer-Vision" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pixels: The Foundations of Computer Vision<a class="anchor-link" href="#Pixels:-The-Foundations-of-Computer-Vision"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we are going to take a look at what we are actually dealing with when it comes to our hand written digits. Thankfully there is a great training set put together by Yann LeCun called the <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a> or Modified National Institute of Standards and Technology database. It contains thousands of individual hand written digits that have been collated as 28px * 28px grayscale images. This is the data we will be using to build our classifier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The team at fastai have made it simple to download and unzip the data we are going to use for this lesson. Instead of having to manually go to the <a href="https://course.fast.ai/datasets">fastai datasets</a> documentation page, download the tar file, unzip it in a location accessible to your notebooks they have a handy <a href="https://github.com/fastai/fastai/blob/715c027b0ad8586feda09e29fb2b483dfe30c910/fastai/data/external.py">utility</a> that will do all of that in single line of code:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The have also added the UNIX <a href="https://en.wikipedia.org/wiki/Ls">ls()</a> function to Python <a href="https://docs.python.org/3/library/pathlib.html">path</a> to give a handy way to see what is in our directory. Here you can see we have our training and validation directory along with a label.csv file.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#3) [Path('valid'),Path('labels.csv'),Path('train')]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Inside each of the training and validation directories we have a folder which contains all of our <strong>3's</strong> and <strong>7's</strong> respectively</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'train'</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#2) [Path('train/7'),Path('train/3')]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can create a list of the file paths and store them in variables</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">threes</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'train'</span><span class="o">/</span><span class="s1">'3'</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span><span class="o">.</span><span class="n">sorted</span><span class="p">()</span>
<span class="n">sevens</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'train'</span><span class="o">/</span><span class="s1">'7'</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span><span class="o">.</span><span class="n">sorted</span><span class="p">()</span>
<span class="n">threes</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take a look at what we are working with. By indexing into the above <strong>threes</strong> list we can retrive the first path in the list. Using <a href="https://pillow.readthedocs.io/en/stable/">PIL</a> the Python Imaging Library, we can display the data at that path.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">im3_path</span> <span class="o">=</span> <span class="n">threes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">im3</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">im3_path</span><span class="p">)</span>
<span class="n">im3</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea output_execute_result">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point it may not be entirely intuative what image information is. It is just an array of values for 0 to 255 for an 8-bit grayscale image like we have above. By casting into a Numpy array and taking a slice we can se what that might look like.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">array</span><span class="p">(</span><span class="n">im3</span><span class="p">)[</span><span class="mi">4</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[  0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  29],
       [  0,   0,   0,  48, 166, 224],
       [  0,  93, 244, 249, 253, 187],
       [  0, 107, 253, 253, 230,  48],
       [  0,   3,  20,  20,  15,   0]], dtype=uint8)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we have seen earlier in the course the PyTorch tensors have very similar functionality to Numpy arrays, but have the added benefit of being pushed to the GPU, this is a optimization and can be used in replacement of standard Numpy arrays. As a huge fan of Numpy my natural propensity is to use them all the time. But I think I need to reconsider . . .</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tensor</span><span class="p">(</span><span class="n">im3</span><span class="p">)[</span><span class="mi">4</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[  0,   0,   0,   0,   0,   0],
        [  0,   0,   0,   0,   0,  29],
        [  0,   0,   0,  48, 166, 224],
        [  0,  93, 244, 249, 253, 187],
        [  0, 107, 253, 253, 230,  48],
        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By loading the tensor into a Pandas Dataframe we are able to see what the pixel values look like by using the .background_gradients method</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">im3_t</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">im3</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">im3_t</span><span class="p">[</span><span class="mi">4</span><span class="p">:</span><span class="mi">15</span><span class="p">,</span><span class="mi">4</span><span class="p">:</span><span class="mi">22</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">set_properties</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="s1">'font-size'</span><span class="p">:</span><span class="s1">'6pt'</span><span class="p">})</span><span class="o">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="s1">'Greys'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<style type="text/css">
#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col5,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col7,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col9,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col11,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col12,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col14,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col7,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col9,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col5,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col7,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col9,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col5,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col7,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col9,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col14,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col5,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col14,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col14,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col16,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col17,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col0,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col5,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col17{
            font-size:  6pt;
            background-color:  #ffffff;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col5{
            font-size:  6pt;
            background-color:  #efefef;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col13{
            font-size:  6pt;
            background-color:  #7c7c7c;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col7{
            font-size:  6pt;
            background-color:  #4a4a4a;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col9,#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col5,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col6,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col7,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col11,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col12,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col12,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col1,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col3,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col12,#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col12,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col11,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col11,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col11,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col12,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col14,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col15,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col16{
            font-size:  6pt;
            background-color:  #000000;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col11{
            font-size:  6pt;
            background-color:  #606060;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col12{
            font-size:  6pt;
            background-color:  #4d4d4d;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col14{
            font-size:  6pt;
            background-color:  #bbbbbb;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col3{
            font-size:  6pt;
            background-color:  #e4e4e4;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col6{
            font-size:  6pt;
            background-color:  #6b6b6b;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col14,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col14{
            font-size:  6pt;
            background-color:  #171717;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col9,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col11{
            font-size:  6pt;
            background-color:  #4b4b4b;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col10{
            font-size:  6pt;
            background-color:  #010101;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col1{
            font-size:  6pt;
            background-color:  #272727;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col2{
            font-size:  6pt;
            background-color:  #0a0a0a;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col3{
            font-size:  6pt;
            background-color:  #050505;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col5{
            font-size:  6pt;
            background-color:  #333333;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col6{
            font-size:  6pt;
            background-color:  #e6e6e6;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col7,#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col10{
            font-size:  6pt;
            background-color:  #fafafa;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col8{
            font-size:  6pt;
            background-color:  #fbfbfb;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col9{
            font-size:  6pt;
            background-color:  #fdfdfd;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col4{
            font-size:  6pt;
            background-color:  #1b1b1b;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col5{
            font-size:  6pt;
            background-color:  #e0e0e0;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col11{
            font-size:  6pt;
            background-color:  #4e4e4e;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col14{
            font-size:  6pt;
            background-color:  #767676;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col1{
            font-size:  6pt;
            background-color:  #fcfcfc;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col2,#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col3{
            font-size:  6pt;
            background-color:  #f6f6f6;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col4,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col7{
            font-size:  6pt;
            background-color:  #f8f8f8;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col7{
            font-size:  6pt;
            background-color:  #e8e8e8;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col11{
            font-size:  6pt;
            background-color:  #222222;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col13,#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col12{
            font-size:  6pt;
            background-color:  #090909;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col14{
            font-size:  6pt;
            background-color:  #d0d0d0;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col10,#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col11,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col6{
            font-size:  6pt;
            background-color:  #060606;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col13{
            font-size:  6pt;
            background-color:  #979797;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col8{
            font-size:  6pt;
            background-color:  #b6b6b6;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col9{
            font-size:  6pt;
            background-color:  #252525;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col12{
            font-size:  6pt;
            background-color:  #999999;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col5{
            font-size:  6pt;
            background-color:  #f9f9f9;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col7{
            font-size:  6pt;
            background-color:  #101010;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col9,#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col9{
            font-size:  6pt;
            background-color:  #020202;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col11{
            font-size:  6pt;
            background-color:  #545454;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col12{
            font-size:  6pt;
            background-color:  #f1f1f1;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col5{
            font-size:  6pt;
            background-color:  #f7f7f7;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col7{
            font-size:  6pt;
            background-color:  #030303;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col12{
            font-size:  6pt;
            background-color:  #181818;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col13{
            font-size:  6pt;
            background-color:  #303030;
            color:  #f1f1f1;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col14{
            font-size:  6pt;
            background-color:  #a9a9a9;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col15{
            font-size:  6pt;
            background-color:  #fefefe;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col8,#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col9{
            font-size:  6pt;
            background-color:  #bababa;
            color:  #000000;
        }#T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col10{
            font-size:  6pt;
            background-color:  #393939;
            color:  #f1f1f1;
        }</style>
<table id="T_be14a70c_3962_11eb_b0e4_0242ac110002">
<thead>    <tr>        <th class="blank level0"></th>        <th class="col_heading level0 col0">0</th>        <th class="col_heading level0 col1">1</th>        <th class="col_heading level0 col2">2</th>        <th class="col_heading level0 col3">3</th>        <th class="col_heading level0 col4">4</th>        <th class="col_heading level0 col5">5</th>        <th class="col_heading level0 col6">6</th>        <th class="col_heading level0 col7">7</th>        <th class="col_heading level0 col8">8</th>        <th class="col_heading level0 col9">9</th>        <th class="col_heading level0 col10">10</th>        <th class="col_heading level0 col11">11</th>        <th class="col_heading level0 col12">12</th>        <th class="col_heading level0 col13">13</th>        <th class="col_heading level0 col14">14</th>        <th class="col_heading level0 col15">15</th>        <th class="col_heading level0 col16">16</th>        <th class="col_heading level0 col17">17</th>    </tr>
</thead>
<tbody>
                <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row0" class="row_heading level0 row0">0</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col0" class="data row0 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col1" class="data row0 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col2" class="data row0 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col3" class="data row0 col3">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col4" class="data row0 col4">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col5" class="data row0 col5">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col6" class="data row0 col6">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col7" class="data row0 col7">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col8" class="data row0 col8">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col9" class="data row0 col9">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col10" class="data row0 col10">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col11" class="data row0 col11">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col12" class="data row0 col12">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col13" class="data row0 col13">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col14" class="data row0 col14">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col15" class="data row0 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col16" class="data row0 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row0_col17" class="data row0 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row1" class="row_heading level0 row1">1</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col0" class="data row1 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col1" class="data row1 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col2" class="data row1 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col3" class="data row1 col3">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col4" class="data row1 col4">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col5" class="data row1 col5">29</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col6" class="data row1 col6">150</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col7" class="data row1 col7">195</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col8" class="data row1 col8">254</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col9" class="data row1 col9">255</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col10" class="data row1 col10">254</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col11" class="data row1 col11">176</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col12" class="data row1 col12">193</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col13" class="data row1 col13">150</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col14" class="data row1 col14">96</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col15" class="data row1 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col16" class="data row1 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row1_col17" class="data row1 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row2" class="row_heading level0 row2">2</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col0" class="data row2 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col1" class="data row2 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col2" class="data row2 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col3" class="data row2 col3">48</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col4" class="data row2 col4">166</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col5" class="data row2 col5">224</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col6" class="data row2 col6">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col7" class="data row2 col7">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col8" class="data row2 col8">234</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col9" class="data row2 col9">196</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col10" class="data row2 col10">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col11" class="data row2 col11">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col12" class="data row2 col12">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col13" class="data row2 col13">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col14" class="data row2 col14">233</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col15" class="data row2 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col16" class="data row2 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row2_col17" class="data row2 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row3" class="row_heading level0 row3">3</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col0" class="data row3 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col1" class="data row3 col1">93</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col2" class="data row3 col2">244</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col3" class="data row3 col3">249</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col4" class="data row3 col4">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col5" class="data row3 col5">187</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col6" class="data row3 col6">46</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col7" class="data row3 col7">10</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col8" class="data row3 col8">8</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col9" class="data row3 col9">4</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col10" class="data row3 col10">10</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col11" class="data row3 col11">194</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col12" class="data row3 col12">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col13" class="data row3 col13">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col14" class="data row3 col14">233</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col15" class="data row3 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col16" class="data row3 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row3_col17" class="data row3 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row4" class="row_heading level0 row4">4</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col0" class="data row4 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col1" class="data row4 col1">107</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col2" class="data row4 col2">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col3" class="data row4 col3">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col4" class="data row4 col4">230</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col5" class="data row4 col5">48</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col6" class="data row4 col6">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col7" class="data row4 col7">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col8" class="data row4 col8">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col9" class="data row4 col9">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col10" class="data row4 col10">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col11" class="data row4 col11">192</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col12" class="data row4 col12">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col13" class="data row4 col13">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col14" class="data row4 col14">156</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col15" class="data row4 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col16" class="data row4 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row4_col17" class="data row4 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row5" class="row_heading level0 row5">5</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col0" class="data row5 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col1" class="data row5 col1">3</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col2" class="data row5 col2">20</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col3" class="data row5 col3">20</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col4" class="data row5 col4">15</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col5" class="data row5 col5">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col6" class="data row5 col6">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col7" class="data row5 col7">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col8" class="data row5 col8">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col9" class="data row5 col9">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col10" class="data row5 col10">43</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col11" class="data row5 col11">224</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col12" class="data row5 col12">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col13" class="data row5 col13">245</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col14" class="data row5 col14">74</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col15" class="data row5 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col16" class="data row5 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row5_col17" class="data row5 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row6" class="row_heading level0 row6">6</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col0" class="data row6 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col1" class="data row6 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col2" class="data row6 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col3" class="data row6 col3">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col4" class="data row6 col4">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col5" class="data row6 col5">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col6" class="data row6 col6">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col7" class="data row6 col7">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col8" class="data row6 col8">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col9" class="data row6 col9">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col10" class="data row6 col10">249</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col11" class="data row6 col11">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col12" class="data row6 col12">245</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col13" class="data row6 col13">126</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col14" class="data row6 col14">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col15" class="data row6 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col16" class="data row6 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row6_col17" class="data row6 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row7" class="row_heading level0 row7">7</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col0" class="data row7 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col1" class="data row7 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col2" class="data row7 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col3" class="data row7 col3">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col4" class="data row7 col4">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col5" class="data row7 col5">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col6" class="data row7 col6">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col7" class="data row7 col7">14</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col8" class="data row7 col8">101</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col9" class="data row7 col9">223</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col10" class="data row7 col10">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col11" class="data row7 col11">248</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col12" class="data row7 col12">124</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col13" class="data row7 col13">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col14" class="data row7 col14">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col15" class="data row7 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col16" class="data row7 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row7_col17" class="data row7 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row8" class="row_heading level0 row8">8</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col0" class="data row8 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col1" class="data row8 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col2" class="data row8 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col3" class="data row8 col3">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col4" class="data row8 col4">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col5" class="data row8 col5">11</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col6" class="data row8 col6">166</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col7" class="data row8 col7">239</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col8" class="data row8 col8">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col9" class="data row8 col9">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col10" class="data row8 col10">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col11" class="data row8 col11">187</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col12" class="data row8 col12">30</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col13" class="data row8 col13">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col14" class="data row8 col14">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col15" class="data row8 col15">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col16" class="data row8 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row8_col17" class="data row8 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row9" class="row_heading level0 row9">9</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col0" class="data row9 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col1" class="data row9 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col2" class="data row9 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col3" class="data row9 col3">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col4" class="data row9 col4">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col5" class="data row9 col5">16</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col6" class="data row9 col6">248</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col7" class="data row9 col7">250</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col8" class="data row9 col8">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col9" class="data row9 col9">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col10" class="data row9 col10">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col11" class="data row9 col11">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col12" class="data row9 col12">232</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col13" class="data row9 col13">213</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col14" class="data row9 col14">111</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col15" class="data row9 col15">2</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col16" class="data row9 col16">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row9_col17" class="data row9 col17">0</td>
            </tr>
            <tr>
                        <th id="T_be14a70c_3962_11eb_b0e4_0242ac110002level0_row10" class="row_heading level0 row10">10</th>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col0" class="data row10 col0">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col1" class="data row10 col1">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col2" class="data row10 col2">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col3" class="data row10 col3">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col4" class="data row10 col4">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col5" class="data row10 col5">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col6" class="data row10 col6">0</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col7" class="data row10 col7">43</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col8" class="data row10 col8">98</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col9" class="data row10 col9">98</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col10" class="data row10 col10">208</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col11" class="data row10 col11">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col12" class="data row10 col12">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col13" class="data row10 col13">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col14" class="data row10 col14">253</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col15" class="data row10 col15">187</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col16" class="data row10 col16">22</td>
                        <td id="T_be14a70c_3962_11eb_b0e4_0242ac110002row10_col17" class="data row10 col17">0</td>
            </tr>
    </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Datatable.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="First-Try:-Pixel-Similarity">
<a class="anchor" href="#First-Try:-Pixel-Similarity" aria-hidden="true"><span class="octicon octicon-link"></span></a>First Try: Pixel Similarity<a class="anchor-link" href="#First-Try:-Pixel-Similarity"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before we start building our model we should consider if there are feasible alternatives to our problem. Working with Deep Learning is like weilding a very large hammer and every problem can appear to us as a nail. But for small self contained problem that do not require scale, simple alternatives are preferable. Here we are exploring an alternative to determine a baseline. What results can we achieve with a naive approach, is this sufficient to solve our problem and can they be improved by the use of a deep learning model. This is an important step, making sure that you are making headway on your problem is more important than having a shiny new model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Problem-Statement">
<a class="anchor" href="#Problem-Statement" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problem Statement<a class="anchor-link" href="#Problem-Statement"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Can we create a simple baseline application that can classify an unseen 28px * 28px image of a <strong>3</strong> or a <strong>7</strong>. Theoretically, this is a simpler task than differentiating between a <strong>3</strong> and an <strong>8</strong> for example because both have similar curves at the top of the number and the bottom which might be difficult to disambiguate. If we try making a <code>mean</code> image from all the data in the <strong>threes</strong> folder and another for the <strong>sevens</strong> and compare the <code>pixel similarity</code> of an unseen image with this <code>mean</code> image we might be able to classify it with some manner of accuracy</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process">
<a class="anchor" href="#Process" aria-hidden="true"><span class="octicon octicon-link"></span></a>Process<a class="anchor-link" href="#Process"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's create two more arrays that store a tensor of each image in our <strong>threes</strong> and <strong>sevens</strong> folders.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seven_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">sevens</span><span class="p">]</span>
<span class="n">three_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">threes</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">three_tensors</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">seven_tensors</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(6131, 6265)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In a similar way to the method above to cast our image to an array or tensor, we can use the fastai <code>show_image</code> method to take a tensor and display it as an image, this will be useful for debugging</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_image</span><span class="p">(</span><span class="n">three_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our next operation is to normalize the values of the images between 0 and 1, first we stack the images on top of one another using <code>torch.stack</code>, convert the integer values in the tensor stack to a float to ensure that values aren't rounded after our division operation, and then we divide the image by 255.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By looking at the shape of the torch tensor stack we can see that we have 6131 image tensors that have 28 rows and 28 columns</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stacked_sevens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">seven_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>
<span class="n">stacked_threes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">three_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>
<span class="n">stacked_threes</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([6131, 28, 28])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The length of the tensor.shape is the same as the tensor rank or number of dimensions, we can see that below by using the <code>ndim</code> method. This is a fast way of checking that your tensors have the correct rank before moving forward building your model or baseline</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">stacked_threes</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stacked_threes</span><span class="o">.</span><span class="n">ndim</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have all of our image tensors stack on top of one another and normalized, we can use the <code>mean</code> method to find the average. By passing in the argument 0, we are telling the operation to take the <code>mean</code> across the first axis. In this example this is the <code>mean</code> of the 6131 images.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean3</span> <span class="o">=</span> <span class="n">stacked_threes</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">show_image</span><span class="p">(</span><span class="n">mean3</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mean7</span> <span class="o">=</span> <span class="n">stacked_sevens</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">show_image</span><span class="p">(</span><span class="n">mean7</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have our <code>mean</code> images, we can compare one of the images against them to see what the <code>pixel similarity</code> is and determine if the image is either a <strong>3</strong> or a <strong>7</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a_3</span> <span class="o">=</span> <span class="n">stacked_threes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">show_image</span><span class="p">(</span><span class="n">a_3</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="L1-and-L2-norm">
<a class="anchor" href="#L1-and-L2-norm" aria-hidden="true"><span class="octicon octicon-link"></span></a>L1 and L2 norm<a class="anchor-link" href="#L1-and-L2-norm"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Take the mean of the absolute value of differences (absolute value is the function that replaces negative values with positive values). This is called the mean absolute difference or L1 norm</li>
<li>Take the mean of the square of differences (which makes everything positive) and then take the square root (which undoes the squaring). This is called the root mean squared error (RMSE) or L2 norm.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To determine the <code>pixel similarity</code> of our test image and our mean image we are going to use the <code>mean absolte difference</code> or the <code>L1 Norm</code> and the <code>root mean squared error</code> or the <code>L2 Norm</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we were simply going to subtract one for the other we could end up with negative values, which once averaged would negate positive values and give us inconcluse information. By comparing the test image againt the mean of the <strong>3's</strong> and the mean of the <strong>7's</strong> we can see that error is lower when comparing to the mean of the <strong>3's</strong> giving us a classification that this image is of a <strong>3</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dist_3_abs</span> <span class="o">=</span> <span class="p">(</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean3</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">dist_3_sqr</span> <span class="o">=</span> <span class="p">((</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean3</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
<span class="n">dist_3_abs</span><span class="p">,</span><span class="n">dist_3_sqr</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(0.1114), tensor(0.2021))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dist_7_abs</span> <span class="o">=</span> <span class="p">(</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean7</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">dist_7_sqr</span> <span class="o">=</span> <span class="p">((</span><span class="n">a_3</span> <span class="o">-</span> <span class="n">mean7</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
<span class="n">dist_7_abs</span><span class="p">,</span><span class="n">dist_7_sqr</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(0.1586), tensor(0.3021))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we can see by using the <code>l1_loss</code> and the <code>mse_loss</code> methods we are getting the same answers our implementations above</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">F</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">a_3</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span><span class="n">mean7</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">a_3</span><span class="p">,</span><span class="n">mean7</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(0.1586), tensor(0.3021))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Computing-Metrics-Using-Broadcasting">
<a class="anchor" href="#Computing-Metrics-Using-Broadcasting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computing Metrics Using Broadcasting<a class="anchor-link" href="#Computing-Metrics-Using-Broadcasting"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point we could simply use a loop and iterate through each of the images in the validation set, calculate the <code>L1</code> loss for each image and determine whether or not our baseline application determines the number to be a <strong>3</strong> or a <strong>7</strong>, check the prediction against and determine an accuracy. This would take a very long time and wouldn't make use of the GPU accelleration needed for Deep Learning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we are going to look at the secret sauce that makes Python (an interpreted language) powerful enough to be used in Deep Learning applications. What is that secret sauce you ask? <code>Broadcasting</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So lets start by stacking the images from our validation directories in the same way we did with our training images. We will normalize them and check the shape of the tensor stack</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_3_tens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> 
                            <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'valid'</span><span class="o">/</span><span class="s1">'3'</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()])</span>
<span class="n">valid_3_tens</span> <span class="o">=</span> <span class="n">valid_3_tens</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>
<span class="n">valid_7_tens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> 
                            <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'valid'</span><span class="o">/</span><span class="s1">'7'</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()])</span>
<span class="n">valid_7_tens</span> <span class="o">=</span> <span class="n">valid_7_tens</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">/</span><span class="mi">255</span>
<span class="n">valid_3_tens</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">valid_7_tens</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we are going to write our <code>L1 Norm</code> in the form of a function, here taking the mean across the rows and columns of the absolute difference of the tow images.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mnist_distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
<span class="n">mnist_distance</span><span class="p">(</span><span class="n">a_3</span><span class="p">,</span> <span class="n">mean3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.1114)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But by using <code>Broadcasting</code>, we can instead use our entire tensor stack and compare it against the <code>mean</code> image of the <strong>3</strong> all at once. What is happening under the hood is that PyTorch is making a "virtual" copy of the mean image tensor for every image tensor in the validation stack so it can determine the <code>pixel similarity</code> for all of them at once. What it returns is a tensor of all of the results.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_3_dist</span> <span class="o">=</span> <span class="n">mnist_distance</span><span class="p">(</span><span class="n">valid_3_tens</span><span class="p">,</span> <span class="n">mean3</span><span class="p">)</span>
<span class="n">valid_3_dist</span><span class="p">,</span> <span class="n">valid_3_dist</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([0.1605, 0.1165, 0.1405,  ..., 0.1159, 0.1183, 0.1471]),
 torch.Size([1010]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now lets create a simple definition to determine if the prediction is a <strong>3</strong> if the result is <code>False</code> then we assume that the image is classified as a <strong>7</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the <code>mnist_distance</code> measured againt the <code>mean</code> <strong>3</strong> is lower than the <code>mean</code> <strong>7</strong> then the function will return <code>True</code></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">is_3</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">mnist_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mean3</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">mnist_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mean7</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here by passing in our test image we can see that it returns <code>True</code>, but by casting it to a float we can get a value instead</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">is_3</span><span class="p">(</span><span class="n">a_3</span><span class="p">),</span> <span class="n">is_3</span><span class="p">(</span><span class="n">a_3</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(True), tensor(1.))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Taking advantage of <code>Broadcasting</code> we can pass the entire tensor stack to the function and we get back an array of predictions</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">is_3</span><span class="p">(</span><span class="n">valid_3_tens</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([False,  True,  True,  ...,  True,  True,  True])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets check the accuracy of our classification application. We are expecting every image tensor in the <code>valid_3_tens</code> tensor to return true and all the image tensors in the <code>valid_7_tens</code> tensor to return false. We can convert them to a floating point value and take the <code>mean</code> to determine the accuracy</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">accuracy_3s</span> <span class="o">=</span>      <span class="n">is_3</span><span class="p">(</span><span class="n">valid_3_tens</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">accuracy_7s</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">is_3</span><span class="p">(</span><span class="n">valid_7_tens</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">accuracy_3s</span><span class="p">,</span><span class="n">accuracy_7s</span><span class="p">,(</span><span class="n">accuracy_3s</span><span class="o">+</span><span class="n">accuracy_7s</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(0.9168), tensor(0.9854), tensor(0.9511))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Wow! It looks like our naive <code>pixel similarity</code> application gives us a <strong>95%</strong> accuracy on this task!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have only used PyTorch for its power tensor operations in this task and proven that with a simple baseline we can determine a highly accurate classifier. Let's see if making a Deep Learning model we can improve the accuracy even further!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Stochastic-Gradient-Descent-(SGD)">
<a class="anchor" href="#Stochastic-Gradient-Descent-(SGD)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stochastic Gradient Descent (SGD)<a class="anchor-link" href="#Stochastic-Gradient-Descent-(SGD)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Up until this point we have a classifier but it really does follow the description by Arthur Samuel</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would "learn" from its experience.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To turn our function into a machine learning classifier we will need:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Initialize the weights.</li>
<li>For each image, use these weights to predict whether it appears to be a 3 or a 7.</li>
<li>Based on these predictions, calculate how good the model is (its loss).</li>
<li>Calculate the gradient, which measures for each weight, how changing that weight would change the loss</li>
<li>Step (that is, change) all the weights based on that calculation.</li>
<li>Go back to the step 2, and repeat the process.</li>
<li>Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer).</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gv</span><span class="p">(</span><span class="s1">'''</span>
<span class="s1">init-&gt;predict-&gt;loss-&gt;gradient-&gt;step-&gt;stop</span>
<span class="s1">step-&gt;predict[label=repeat]</span>
<span class="s1">'''</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewbox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4"></polygon>
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18"></ellipse>
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init-&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18"></path>
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5"></polygon>
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18"></ellipse>
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict-&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14"></path>
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49"></polygon>
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18"></ellipse>
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss-&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52"></path>
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5"></polygon>
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18"></ellipse>
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient-&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71"></path>
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06"></polygon>
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step-&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18"></path>
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5"></polygon>
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18"></ellipse>
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step-&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18"></path>
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5"></polygon>
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/SGD.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To understand <code>SGD</code> a little better lets start with a simpler example using this quadratic function:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's plot what that function looks like:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_function</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">,</span> <span class="s1">'x**2'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/conda/envs/fastai/lib/python3.8/site-packages/fastbook/__init__.py:73: UserWarning: Not providing a value for linspace's steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729096996/work/aten/src/ATen/native/RangeFactories.cpp:23.)
  x = torch.linspace(min,max)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sequence of steps we described earlier starts by picking some random value for a parameter, and calculating the value of the loss:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_function</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">,</span> <span class="s1">'x**2'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we look to see what would happen if we increased or decreased our parameter by a little bit—the adjustment. This is simply the slope at a particular point:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Slope.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can change our weight by a little in the direction of the slope, calculate our loss and adjustment again, and repeat this a few times. Eventually, we will get to the lowest point on our curve:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Gradient.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This basic idea goes all the way back to Isaac Newton, who pointed out that we can optimize arbitrary functions in this way</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Calculating-Gradients">
<a class="anchor" href="#Calculating-Gradients" aria-hidden="true"><span class="octicon octicon-link"></span></a>Calculating Gradients<a class="anchor-link" href="#Calculating-Gradients"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>This is a lot of text from this portion of the book, its <strong>really</strong> important and I getting it right is paramount</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>"The one magic step is the bit where we calculate the gradients. As we mentioned, we use calculus as a performance optimization; it allows us to more quickly calculate whether our loss will go up or down when we adjust our parameters up or down. In other words, the gradients will tell us how much we have to change each weight to make our model better."</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Thankfully PyTorch is a very powerful auto-differential library. It utilises the <a href="https://medium.com/machine-learning-and-math/deep-learning-and-chain-rule-of-calculus-80896a1e91f9">Chain Rule</a> to <a href="https://pytorch.org/docs/stable/notes/autograd.html">calculate the derivative</a> of our functions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, let's pick a tensor value which we want gradients at:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xt</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">3.</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice the special method requires<em>grad</em>? That's the magical incantation we use to tell PyTorch that we want to calculate gradients with respect to that variable at that value. It is essentially tagging the variable, so PyTorch will remember to keep track of how to compute gradients of the other, direct calculations on it that you will ask for.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This API might throw you off if you're coming from math or physics. In those contexts the "gradient" of a function is just another function (i.e., its derivative), so you might expect gradient-related APIs to give you a new function. <strong>But in deep learning, "gradients" usually means the value of a function's derivative at a particular argument value</strong>. The PyTorch API also puts the focus on the argument, not the function you're actually computing the gradients of. It may feel backwards at first, but it's just a different perspective.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we calculate our function with that value. Notice how PyTorch prints not just the value calculated, but also a note that it has a gradient function it'll be using to calculate our gradients when needed:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yt</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
<span class="n">yt</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(9., grad_fn=&lt;PowBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Calculating the derivative value of our function at this input tensor is simple, we just call the <code>backward</code> method.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yt</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The "backward" here refers to backpropagation, which is the name given to the process of calculating the derivative of each layer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now view the gradients by checking the grad attribute of our tensor:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xt</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(6.)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you remember your high school calculus rules, the derivative of x<em>**2 is 2</em>x, and we have x=3, so the gradients should be 2*3=6, which is what PyTorch calculated for us!</p>
<p>Now we'll repeat the preceding steps, but with a vector argument for our function:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xt</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">,</span><span class="mf">10.</span><span class="p">])</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="n">xt</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 3.,  4., 10.], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we'll add sum to our function so it can take a vector (i.e., a rank-1 tensor), and return a scalar (i.e., a rank-0 tensor):</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">yt</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
<span class="n">yt</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(125., grad_fn=&lt;SumBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our gradients are 2*xt, as we'd expect!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yt</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">xt</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 6.,  8., 20.])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The gradients only tell us the slope of our function, they don't actually tell us exactly how far to adjust the parameters. But it gives us some idea of how far; if the slope is very large, then that may suggest that we have more adjustments to do, whereas if the slope is very small, that may suggest that we are close to the optimal value.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Stepping-With-a-Learning-Rate">
<a class="anchor" href="#Stepping-With-a-Learning-Rate" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stepping With a Learning Rate<a class="anchor-link" href="#Stepping-With-a-Learning-Rate"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Because our gradient only shows the slope, or the direction, in which we need to change our parameters. We will need to figure out how much we move in this direction. This is where we introduce the learning rate. The learning rate is often a number between 0.001 and 0.1, although it could be anything.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once you've picked a learning rate, you can adjust your parameters using this simple function:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span> <span class="o">-=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="n">lr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you pick a learning rate that's too low, it can mean having to do a lot of steps</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Small_Step.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But picking a learning rate that's too high is even worse—it can actually result in the loss getting worse</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Large_Step.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the learning rate is too high, it may also "bounce" around, rather than actually diverging</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Bounce.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="An-End-to-End-SGD-Example">
<a class="anchor" href="#An-End-to-End-SGD-Example" aria-hidden="true"><span class="octicon octicon-link"></span></a>An End-to-End SGD Example<a class="anchor-link" href="#An-End-to-End-SGD-Example"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's work through a practical example from end-to-end. First we will make a float tensor that represents our time variable. Each index is a time in seconds</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">();</span> <span class="n">time</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we create a quadratic function, a function of the form a<em>(time**</em>2)+(b*time)+c,  and add some noiose to simulate realworld measurments</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">speed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span> <span class="o">+</span> <span class="mf">0.75</span><span class="o">*</span><span class="p">(</span><span class="n">time</span><span class="o">-</span><span class="mf">9.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">time</span><span class="p">,</span><span class="n">speed</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We want to distinguish clearly between the function's input (the time when we are measuring the coaster's speed) and its parameters (the values that define which quadratic we're trying). So, let's collect the parameters in one argument and thus separate the input, t, and the parameters, params, in the function's signature:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span> <span class="o">=</span> <span class="n">params</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">b</span><span class="o">*</span><span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="n">c</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need to determine which loss function we would like to use. For continuous data, it's common to use mean squared error:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span> <span class="k">return</span> <span class="p">((</span><span class="n">preds</span><span class="o">-</span><span class="n">targets</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-1:-Initialize-the-parameters">
<a class="anchor" href="#Step-1:-Initialize-the-parameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 1: Initialize the parameters<a class="anchor-link" href="#Step-1:-Initialize-the-parameters"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First thing we want to do is create a tensor for our parameters and to tell PyTorch that this tensor <code>requires_grad_()</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-2:-Calculate-the-predictions">
<a class="anchor" href="#Step-2:-Calculate-the-predictions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 2: Calculate the predictions<a class="anchor-link" href="#Step-2:-Calculate-the-predictions"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets pass our time tensor and our params into our function</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we are creating a small matplotlib function to show a comparison between our predictions and our observations</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_preds</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">speed</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">to_np</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">300</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_preds</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-3:-Calculate-the-loss">
<a class="anchor" href="#Step-3:-Calculate-the-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 3: Calculate the loss<a class="anchor-link" href="#Step-3:-Calculate-the-loss"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can use our <code>L2</code> or <code>RMSE</code> function to determine our loss</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">speed</span><span class="p">)</span>
<span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-4:-Calculate-the-gradients">
<a class="anchor" href="#Step-4:-Calculate-the-gradients" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 4: Calculate the gradients<a class="anchor-link" href="#Step-4:-Calculate-the-gradients"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By performing <code>Back Propogation</code> with our <code>backward()</code> method on the loss, we can calculate the slope of our gradient and which direction the we need to move in to improve our loss</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">params</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([-165.5151,  -10.6402,   -0.7900])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we use a small learning rate and multiply that to our parameter's gradient to make sure we move towards the optimal solution over each iteration</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="mf">1e-5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([-1.6552e-03, -1.0640e-04, -7.8996e-06])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([-0.7658, -0.7506,  1.3525], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-5:-Step-the-weights.">
<a class="anchor" href="#Step-5:-Step-the-weights." aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 5: Step the weights.<a class="anchor-link" href="#Step-5:-Step-the-weights."> </a>
</h4>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">params</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">params</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
<span class="n">params</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Understanding this bit depends on remembering recent history. To calculate the gradients we call backward on the loss. But this loss was itself calculated by mse, which in turn took preds as an input, which was calculated using f taking as an input params, which was the object on which we originally called required<em>grads</em>—which is the original call that now allows us to call backward on loss. This chain of function calls represents the mathematical composition of functions, which enables PyTorch to use calculus's chain rule under the hood to calculate these gradients.</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">time</span><span class="p">,</span><span class="n">params</span><span class="p">)</span>
<span class="n">mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">speed</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(160.4228, grad_fn=&lt;SqrtBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_preds</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here we simply wrap our previous steps into a function</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Make a prediction</li>
<li>Calculate the loss</li>
<li>Perform back propogation on the loss, see above for details</li>
<li>Apply the learning rate </li>
<li>Zero our gradients</li>
<li>Return our predictions</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">apply_step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">prn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">speed</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">params</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">params</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
    <span class="n">params</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">prn</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">preds</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-6:-Repeat-the-process">
<a class="anchor" href="#Step-6:-Repeat-the-process" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 6: Repeat the process<a class="anchor-link" href="#Step-6:-Repeat-the-process"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we simply call our <code>apply_step</code> function a number of times, as we can see our loss improves each iteration</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">apply_step</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>155.75035095214844
155.4757537841797
155.20118713378906
154.92662048339844
154.65211486816406
154.37762451171875
154.1031494140625
153.82872009277344
153.55430603027344
153.27992248535156
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span><span class="p">,</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="p">:</span> <span class="n">show_preds</span><span class="p">(</span><span class="n">apply_step</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Step-7:-stop">
<a class="anchor" href="#Step-7:-stop" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 7: stop<a class="anchor-link" href="#Step-7:-stop"> </a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Either we can stop after a certain accuracy or simply after a number of iterations</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Summarizing-Gradient-Descent">
<a class="anchor" href="#Summarizing-Gradient-Descent" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summarizing Gradient Descent<a class="anchor-link" href="#Summarizing-Gradient-Descent"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gv</span><span class="p">(</span><span class="s1">'''</span>
<span class="s1">init-&gt;predict-&gt;loss-&gt;gradient-&gt;step-&gt;stop</span>
<span class="s1">step-&gt;predict[label=repeat]</span>
<span class="s1">'''</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewbox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4"></polygon>
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18"></ellipse>
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18"></ellipse>
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init-&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18"></path>
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5"></polygon>
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18"></ellipse>
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict-&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14"></path>
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49"></polygon>
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18"></ellipse>
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss-&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52"></path>
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5"></polygon>
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18"></ellipse>
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient-&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71"></path>
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06"></polygon>
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step-&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18"></path>
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5"></polygon>
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18"></ellipse>
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step-&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18"></path>
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5"></polygon>
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/SGD.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Initialize the weights.</li>
<li>For each image, use these weights to predict whether it appears to be a 3 or a 7.</li>
<li>Based on these predictions, calculate how good the model is (its loss).</li>
<li>Calculate the gradient, which measures for each weight, how changing that weight would change the loss</li>
<li>Step (that is, change) all the weights based on that calculation.</li>
<li>Go back to the step 2, and repeat the process.</li>
<li>Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer).</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To summarize, at the beginning, the weights of our model can be random (training from scratch) or come from a pretrained model (transfer learning). In the first case, the output we will get from our inputs won't have anything to do with what we want, and even in the second case, it's very likely the pretrained model won't be very good at the specific task we are targeting. So the model will need to learn better weights.</p>
<p>We begin by comparing the outputs the model gives us with our targets (we have labeled data, so we know what result the model should give) using a loss function, which returns a number that we want to make as low as possible by improving our weights. To do this, we take a few data items (such as images) from the training set and feed them to our model. We compare the corresponding targets using our loss function, and the score we get tells us how wrong our predictions were. We then change the weights a little bit to make it slightly better.</p>
<p>To find how to change the weights to make the loss a bit better, we use calculus to calculate the gradients. (Actually, we let PyTorch do it for us!) Let's consider an analogy. Imagine you are lost in the mountains with your car parked at the lowest point. To find your way back to it, you might wander in a random direction, but that probably wouldn't help much. Since you know your vehicle is at the lowest point, you would be better off going downhill. By always taking a step in the direction of the steepest downward slope, you should eventually arrive at your destination. We use the magnitude of the gradient (i.e., the steepness of the slope) to tell us how big a step to take; specifically, we multiply the gradient by a number we choose called the learning rate to decide on the step size. We then iterate until we have reached the lowest point, which will be our parking lot, then we can stop.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-MNIST-Loss-Function">
<a class="anchor" href="#The-MNIST-Loss-Function" aria-hidden="true"><span class="octicon octicon-link"></span></a>The MNIST Loss Function<a class="anchor-link" href="#The-MNIST-Loss-Function"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have seen how the mothod works on a simple function, we can now put this into practice on our MNIST <strong>3's</strong> and <strong>7's</strong> problem. As we have our dependent variable x:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Remember:</p>
<ul>
<li>
<strong>Dependent Variable</strong> == input variables</li>
<li>
<strong>Independent Varibale</strong> == output variables</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our dependent variable in this is example are the images themselves. Here we concatinate the stacked image tensors of the <strong>3's</strong> and the <strong>7's</strong>. Having the image as Matrix is irrelevant we can use the Pytorch <code>view</code> method to reshape every tensor to rank 1,</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">stacked_threes</span><span class="p">,</span> <span class="n">stacked_sevens</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also need a label for each of the images, here we can simply create a tensor by combining an array of 1's of length of the number of <strong>3's</strong> and an array of 0's the length of the number of <strong>7's</strong>. We use the PyTorch function <code>unsqueeze</code> to transpose the tensor from a vector with 123396 elements into a tensor with 12396 rows and a single column</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">threes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">sevens</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">train_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([12396, 784]), torch.Size([12396, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we need to create a dataset, a dataset needs to be able to be indexable, and at that index we expect a tuple (data, label). Here we are using the python <code>zip</code> function to take the <code>train_x</code> and <code>train_y</code> varibles and combine them into a tuple at each index as described</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">))</span>
<span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([784]), tensor([1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need to do the same operations above for our validation set as well</p>
<ul>
<li>Concatinate the images and reshape</li>
<li>Create labels and unsqueeze</li>
<li>Zip data and label into dataset</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">valid_3_tens</span><span class="p">,</span> <span class="n">valid_7_tens</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">valid_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_3_tens</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_7_tens</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">valid_dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">valid_x</span><span class="p">,</span><span class="n">valid_y</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here is a simple function that will initialize our parameters with random values. PyTorch <code>randn</code> returns a tensor the shape and size of its argument with normalized values between 0 and 1. We can use a variance argument here to scale the random values if necessary, but not in this example. We want to be able to calculate the gradient of this tensor, so we use the <code>requires_grad</code> method</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We create and initialize our weights and bias variables</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bias</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In neural networks, the w in the equation y=w*x+b is called the weights, and the b is called the bias. Together, the weights and bias make up the parameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now calculate a prediction for one image:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">train_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">bias</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([20.2336], grad_fn=&lt;AddBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>While we could use a Python for loop to calculate the prediction for each image, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.</p>
<p>In this case, there's an extremely convenient mathematical operation that calculates w*x for every row of a matrix—it's called matrix multiplication.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Matmul.gif" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In Python, matrix multiplication is represented with the @ operator. Let's try it:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">linear1</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span> <span class="k">return</span> <span class="n">xb</span><span class="nd">@weights</span> <span class="o">+</span> <span class="n">bias</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">linear1</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="n">preds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[20.2336],
        [17.0644],
        [15.2384],
        ...,
        [18.3804],
        [23.8567],
        [28.6816]], grad_fn=&lt;AddBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets check how good our random initialization is. Here is make a determination that if a prediction is over 0 it's a <strong>3</strong> else its a <strong>7</strong> and we compare it against our labels</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corrects</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">==</span> <span class="n">train_y</span>
<span class="n">corrects</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ True],
        [ True],
        [ True],
        ...,
        [False],
        [False],
        [False]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, and could have predicted, a random initilization is correct roughly 50% of the time.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corrects</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.4912068545818329</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So lets change one of our parameters a little bit and see if that changes our result</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">1.0001</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">linear1</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="p">((</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">==</span> <span class="n">train_y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.4912068545818329</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see above changing one parameter a little has absolutely no affect on the results of our network. What does this mean practically?</p>
<p>By changing this pixel by some small amount is not sufficient in itself to change the prediction of an image from a <strong>3</strong> to a <strong>7</strong></p>
<p>Becaue there is no change we cannot calculate a gradient and we cannot make a step to improve our predictions. This is because of the thresholding in our determining our correctness.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>In mathematical terms, accuracy is a function that is constant almost everywhere (except at the threshold, 0.5), so its derivative is nil almost everywhere (and infinity at the threshold). This then gives gradients that are 0 or infinite, which are useless for updating the model.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So how do we fix this?</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trgts</span>  <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">prds</span>   <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's a first try at a loss function that measures the distance between predictions and targets:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mnist_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">predictions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Read the Docs: It's important to learn about PyTorch functions like this, because looping over tensors in Python performs at Python speed, not C/CUDA speed! Try running help(torch.where) now to read the docs for this function, or, better still, look it up on the PyTorch documentation site.</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">trgts</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">prds</span><span class="p">,</span> <span class="n">prds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([0.1000, 0.4000, 0.8000])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see that this function returns a lower number when predictions are more accurate, when accurate predictions are more confident (higher absolute values), and when inaccurate predictions are less confident. In PyTorch, we always assume that a lower value of a loss function is better. Since we need a scalar for the final loss, mnist_loss takes the mean of the previous tensor:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mnist_loss</span><span class="p">(</span><span class="n">prds</span><span class="p">,</span><span class="n">trgts</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.4333)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For instance, if we change our prediction for the one "false" target from 0.2 to 0.8 the loss will go down, indicating that this is a better prediction:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mnist_loss</span><span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]),</span><span class="n">trgts</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.2333)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One problem with mnist_loss as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is actually the case! As it happens, there is a function that does exactly that—let's take a look.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Sigmoid">
<a class="anchor" href="#Sigmoid" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sigmoid<a class="anchor-link" href="#Sigmoid"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sigmoid function always outputs a number between 0 and 1. It's defined as follows:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_function</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'Sigmoid'</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">4</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, it takes any input value, positive or negative, and smooshes it onto an output value between 0 and 1. It's also a smooth curve that only goes up, which makes it easier for SGD to find meaningful gradients.</p>
<p>Let's update mnist_loss to first apply sigmoid to the inputs:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mnist_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">predictions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="SGD-and-Mini-Batches">
<a class="anchor" href="#SGD-and-Mini-Batches" aria-hidden="true"><span class="octicon octicon-link"></span></a>SGD and Mini-Batches<a class="anchor-link" href="#SGD-and-Mini-Batches"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the context of SGD, "Minibatch" means that the gradient is calculated across the entire batch before updating weights. If you are not using a "minibatch", every training example in a "batch" updates the learning algorithm's parameters independently.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">coll</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">coll</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[tensor([ 3, 12,  8, 10,  2]),
 tensor([ 9,  4,  7, 14,  5]),
 tensor([ 1, 13,  0,  6, 11])]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">))</span>
<span class="n">ds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">list</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(tensor([17, 18, 10, 22,  8, 14]), ('r', 's', 'k', 'w', 'i', 'o')),
 (tensor([20, 15,  9, 13, 21, 12]), ('u', 'p', 'j', 'n', 'v', 'm')),
 (tensor([ 7, 25,  6,  5, 11, 23]), ('h', 'z', 'g', 'f', 'l', 'x')),
 (tensor([ 1,  3,  0, 24, 19, 16]), ('b', 'd', 'a', 'y', 't', 'q')),
 (tensor([2, 4]), ('c', 'e'))]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Putting-It-All-Together">
<a class="anchor" href="#Putting-It-All-Together" aria-hidden="true"><span class="octicon octicon-link"></span></a>Putting It All Together<a class="anchor-link" href="#Putting-It-All-Together"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, let's re-initialize our parameters:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A DataLoader can be created from a Dataset and we can set our bacth size here:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="o">=</span> <span class="n">first</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>
<span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">yb</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([256, 784]), torch.Size([256, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll do the same for the validation set:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's create a mini-batch of size 4 for testing:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch</span> <span class="o">=</span> <span class="n">train_x</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
<span class="n">batch</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([4, 784])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">linear1</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="n">preds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-2.1876],
        [-8.3973],
        [ 2.5000],
        [-4.9473]], grad_fn=&lt;AddBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">mnist_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">train_y</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
<span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.7419, grad_fn=&lt;MeanBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can calculate the gradients:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">weights</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">weights</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([784, 1]), tensor(-0.0061), tensor([-0.0420]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's put this into a function:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mnist_loss</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">calc_grad</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">train_y</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span> <span class="n">linear1</span><span class="p">)</span>
<span class="n">weights</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(-0.0121), tensor([-0.0840]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But look what happens if we call it twice:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">calc_grad</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">train_y</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span> <span class="n">linear1</span><span class="p">)</span>
<span class="n">weights</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor(-0.0182), tensor([-0.1260]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The gradients have changed! The reason for this is that loss.backward actually adds the gradients of loss to any gradients that are currently stored. So, we have to set the current gradients to 0 first:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Inplace Operations: Methods in PyTorch whose names end in an underscore modify their objects in place. For instance, bias.zero_() sets all elements of the tensor bias to 0.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our only remaining step is to update the weights and biases based on the gradient and learning rate. When we do so, we have to tell PyTorch not to take the gradient of this step too—otherwise things will get very confusing when we try to compute the derivative at the next batch!</p>
<p><strong>If we assign to the data attribute of a tensor then PyTorch will not take the gradient of that step. Here's our basic training loop for an epoch:</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">*</span><span class="n">lr</span>
            <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also want to check how we're doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0. So our accuracy for each item can be calculated (using broadcasting, so no loops!) with:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">==</span> <span class="n">train_y</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[False],
        [False],
        [ True],
        [False]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That gives us this function to calculate our validation accuracy:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">batch_accuracy</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">xb</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">yb</span>
    <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_accuracy</span><span class="p">(</span><span class="n">linear1</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">train_y</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.2500)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>and then put the batches together:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.5263</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's our starting point. Let's train for one epoch, and see if the accuracy improves:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">weights</span><span class="p">,</span><span class="n">bias</span>
<span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.6663</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then do a few more:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">train_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear1</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.8265 0.89 0.9183 0.9276 0.9398 0.9467 0.9506 0.9525 0.9559 0.9579 0.9598 0.9608 0.9613 0.9618 0.9633 0.9637 0.9647 0.9657 0.9672 0.9677 </pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking good! We're already about at the same accuracy as our "pixel similarity" approach, and we've created a general-purpose foundation we can build on. Our next step will be to create an object that will handle the SGD step for us. In PyTorch, it's called an optimizer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-an-Optimizer">
<a class="anchor" href="#Creating-an-Optimizer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating an Optimizer<a class="anchor-link" href="#Creating-an-Optimizer"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>PyTorch's <code>nn.Linear</code> does the same thing as our init_params and linear together. It contains both the weights and biases in a single class. Here's how we replicate our model from the previous section:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">linear_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Every PyTorch module knows what parameters it has that can be trained; they are available through the parameters method:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([1, 784]), torch.Size([1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, let's create an optimizer:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">BasicOptim</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">params</span><span class="p">,</span><span class="n">lr</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">params</span><span class="p">),</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can create our optimizer by passing in the model's parameters:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">BasicOptim</span><span class="p">(</span><span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">linear_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.4606</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_model</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.4932 0.7685 0.8554 0.9136 0.9346 0.9482 0.957 0.9634 0.9658 0.9678 0.9697 0.9717 0.9736 0.9746 0.9761 0.977 0.9775 0.9775 0.978 0.9785 </pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>fastai provides the SGD class which, by default, does the same thing as our BasicOptim:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">linear_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">linear_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
<span class="n">train_model</span><span class="p">(</span><span class="n">linear_model</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.4932 0.8179 0.8496 0.914 0.9346 0.9482 0.957 0.9619 0.9658 0.9673 0.9692 0.9712 0.9741 0.9751 0.9761 0.9775 0.9775 0.978 0.9785 0.979 </pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>fastai also provides Learner.fit, which we can use instead of train_model. To create a Learner we first need to create a DataLoaders, by passing in our training and validation DataLoaders:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To create a Learner without using an application (such as cnn_learner) we need to pass in all the elements that we've created in this chapter: the DataLoaders, the model, the optimization function (which will be passed the parameters), the loss function, and optionally any metrics to print:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span>
                <span class="n">loss_func</span><span class="o">=</span><span class="n">mnist_loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>batch_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.636709</td>
      <td>0.503144</td>
      <td>0.495584</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.429828</td>
      <td>0.248517</td>
      <td>0.777233</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.161680</td>
      <td>0.155361</td>
      <td>0.861629</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.072948</td>
      <td>0.097721</td>
      <td>0.917566</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.040128</td>
      <td>0.073205</td>
      <td>0.936212</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.027210</td>
      <td>0.059466</td>
      <td>0.950442</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.021837</td>
      <td>0.050799</td>
      <td>0.957802</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.019398</td>
      <td>0.044980</td>
      <td>0.964181</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.018122</td>
      <td>0.040853</td>
      <td>0.966143</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.017330</td>
      <td>0.037788</td>
      <td>0.968106</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Adding-a-Nonlinearity">
<a class="anchor" href="#Adding-a-Nonlinearity" aria-hidden="true"><span class="octicon octicon-link"></span></a>Adding a Nonlinearity<a class="anchor-link" href="#Adding-a-Nonlinearity"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So far we have a general procedure for optimizing the parameters of a function, and we have tried it out on a very boring function: a simple linear classifier. A linear classifier is very constrained in terms of what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something nonlinear between two linear classifiers—this is what gives us a neural network.</p>
<p>Here is the entire definition of a basic neural network:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">simple_net</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span> 
    <span class="n">res</span> <span class="o">=</span> <span class="n">xb</span><span class="nd">@w1</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="nd">@w2</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="k">return</span> <span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's it! All we have in simple_net is two linear classifiers with a max function between them.</p>
<p>Here, w1 and w2 are weight tensors, and b1 and b2 are bias tensors; that is, parameters that are initially randomly initialized, just like we did in the previous section:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w1</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">))</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="n">w2</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The key point about this is that w1 has 30 output activations (which means that w2 must have 30 input activations, so they match). That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that 30 to anything you like, to make the model more or less complex.</p>
<p>That little function res.max(tensor(0.0)) is called a rectified linear unit, also known as ReLU. We think we can all agree that rectified linear unit sounds pretty fancy and complicated... But actually, there's nothing more to it than res.max(tensor(0.0))—in other words, replace every negative number with a zero. This tiny function is also available in PyTorch as F.relu:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_function</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Mathematically, we say the composition of two linear functions is another linear function. So, we can stack as many linear classifiers as we want on top of each other, and without nonlinear functions between them, it will just be the same as one linear classifier.</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">simple_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>nn.Sequential creates a module that will call each of the listed layers or functions in turn.</p>
<p>nn.ReLU is a PyTorch module that does exactly the same thing as the F.relu function. Most functions that can appear in a model also have identical forms that are modules. Generally, it's just a case of replacing F with nn and changing the capitalization. When using nn.Sequential, PyTorch requires us to use the module version. Since modules are classes, we have to instantiate them, which is why you see nn.ReLU() in this example.</p>
<p>Because nn.Sequential is a module, we can get its parameters, which will return a list of all the parameters of all the modules it contains. Let's try it out! As this is a deeper model, we'll use a lower learning rate and a few more epochs.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">simple_net</span><span class="p">,</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">SGD</span><span class="p">,</span>
                <span class="n">loss_func</span><span class="o">=</span><span class="n">mnist_loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>batch_accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.333021</td>
      <td>0.396112</td>
      <td>0.512267</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.152461</td>
      <td>0.235238</td>
      <td>0.797350</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.083573</td>
      <td>0.117471</td>
      <td>0.911678</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.054309</td>
      <td>0.078720</td>
      <td>0.940628</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.040829</td>
      <td>0.061228</td>
      <td>0.956330</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.034006</td>
      <td>0.051490</td>
      <td>0.963690</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.030123</td>
      <td>0.045381</td>
      <td>0.966634</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.027619</td>
      <td>0.041218</td>
      <td>0.968106</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.025825</td>
      <td>0.038200</td>
      <td>0.969087</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.024441</td>
      <td>0.035901</td>
      <td>0.969578</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.023321</td>
      <td>0.034082</td>
      <td>0.971541</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.022387</td>
      <td>0.032598</td>
      <td>0.972031</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.021592</td>
      <td>0.031353</td>
      <td>0.974485</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.020904</td>
      <td>0.030284</td>
      <td>0.975466</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.020300</td>
      <td>0.029352</td>
      <td>0.975466</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.019766</td>
      <td>0.028526</td>
      <td>0.975466</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.019288</td>
      <td>0.027788</td>
      <td>0.976448</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.018857</td>
      <td>0.027124</td>
      <td>0.977429</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.018465</td>
      <td>0.026523</td>
      <td>0.978410</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.018107</td>
      <td>0.025977</td>
      <td>0.978901</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.017777</td>
      <td>0.025479</td>
      <td>0.978901</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.017473</td>
      <td>0.025022</td>
      <td>0.979392</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.017191</td>
      <td>0.024601</td>
      <td>0.980373</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.016927</td>
      <td>0.024213</td>
      <td>0.980373</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.016680</td>
      <td>0.023855</td>
      <td>0.981354</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.016449</td>
      <td>0.023521</td>
      <td>0.981354</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.016230</td>
      <td>0.023211</td>
      <td>0.981354</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.016023</td>
      <td>0.022922</td>
      <td>0.981354</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.015827</td>
      <td>0.022653</td>
      <td>0.981845</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.015641</td>
      <td>0.022401</td>
      <td>0.981845</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>30</td>
      <td>0.015463</td>
      <td>0.022165</td>
      <td>0.981845</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>31</td>
      <td>0.015294</td>
      <td>0.021944</td>
      <td>0.983317</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>32</td>
      <td>0.015132</td>
      <td>0.021736</td>
      <td>0.982826</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>33</td>
      <td>0.014977</td>
      <td>0.021541</td>
      <td>0.982826</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>34</td>
      <td>0.014828</td>
      <td>0.021357</td>
      <td>0.982336</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>35</td>
      <td>0.014686</td>
      <td>0.021184</td>
      <td>0.982336</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>36</td>
      <td>0.014549</td>
      <td>0.021019</td>
      <td>0.982336</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>37</td>
      <td>0.014417</td>
      <td>0.020864</td>
      <td>0.982336</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>38</td>
      <td>0.014290</td>
      <td>0.020716</td>
      <td>0.982336</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>39</td>
      <td>0.014168</td>
      <td>0.020576</td>
      <td>0.982336</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">L</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">itemgot</span><span class="p">(</span><span class="mi">2</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we can view the final accuracy:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.98233562707901</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point we have something that is rather magical:</p>
<p>A function that can solve any problem to any level of accuracy (the neural network) given the correct set of parameters
A way to find the best set of parameters for any function (stochastic gradient descent)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Going-Deeper">
<a class="anchor" href="#Going-Deeper" aria-hidden="true"><span class="octicon octicon-link"></span></a>Going Deeper<a class="anchor-link" href="#Going-Deeper"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here what happens when we train an 18-layer model . . .</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">ImageDataLoaders</span><span class="o">.</span><span class="n">from_folder</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">loss_func</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.128586</td>
      <td>0.037928</td>
      <td>0.996075</td>
      <td>00:16</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Almost 100% accuracy!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Jargon-Recap">
<a class="anchor" href="#Jargon-Recap" aria-hidden="true"><span class="octicon octicon-link"></span></a>Jargon Recap<a class="anchor-link" href="#Jargon-Recap"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<strong>ReLU :</strong> Function that returns 0 for negative numbers and doesn't change positive numbers.</li>
<li>
<strong>Mini-batch :</strong> A small group of inputs and labels gathered together in two arrays. A gradient descent step is updated on this batch (rather than a whole epoch).</li>
<li>
<strong>Forward pass :</strong> Applying the model to some input and computing the predictions.</li>
<li>
<strong>Loss :</strong> A value that represents how well (or badly) our model is doing.</li>
<li>
<strong>Gradient :</strong> The derivative of the loss with respect to some parameter of the model.</li>
<li>
<strong>Backward pass :</strong> Computing the gradients of the loss with respect to all model parameters.</li>
<li>
<strong>Gradient descent :</strong> Taking a step in the directions opposite to the gradients to make the model parameters a little bit better.</li>
<li>
<strong>Learning rate :</strong> The size of the step we take when applying SGD to update the parameters of the model.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Questionnaire">
<a class="anchor" href="#Questionnaire" aria-hidden="true"><span class="octicon octicon-link"></span></a>Questionnaire<a class="anchor-link" href="#Questionnaire"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>How is a grayscale image represented on a computer? How about a color image?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Images are represented by arrays with pixel values representing the content of the image. For greyscale images, a 2-dimensional array is used with the pixels representing the greyscale values, with a range of 256 integers. A value of 0 would represent white, and a value of 255 represents black, and different shades of greyscale in between. For color images, three color channels (red, green, blue) are typicall used, with a separate 256-range 2D array used for each channel. A pixel value of 0 again represents white, with 255 representing solid red, green, or blue. The three 2-D arrays form a final 3-D array (rank 3 tensor) representing the color image.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>How are the files and folders in the <code>MNIST_SAMPLE</code> dataset structured? Why?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two subfolders, train and valid, the former contains the data for model training, the latter contains the data for validating model performance after each training step. Evaluating the model on the validation set serves two purposes: a) to report a human-interpretable metric such as accuracy (in contrast to the often abstract loss functions used for training), b) to facilitate the detection of overfitting by evaluating the model on a dataset it hasn’t been trained on (in short, an overfitting model performs increasingly well on the training set but decreasingly so on the validation set). Of course, every practicioner could generate their own train/validation-split of the data. Public datasets are usually pre-split to simplifiy comparing results between implementations/publications.</p>
<p>Each subfolder has two subsubfolders 3 and 7 which contain the .jpg files for the respective class of images. This is a common way of organizing datasets comprised of pictures. For the full MNIST dataset there are 10 subsubfolders, one for the images for each digit.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Explain how the "pixel similarity" approach to classifying digits works.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the “pixel similarity” approach, we generate an archetype for each class we want to identify. In our case, we want to distinguish images of 3’s from images of 7’s. We define the archetypical 3 as the pixel-wise mean value of all 3’s in the training set. Analoguously for the 7’s. You can visualize the two archetypes and see that they are in fact blurred versions of the numbers they represent.
In order to tell if a previously unseen image is a 3 or a 7, we calculate its distance to the two archetypes (here: mean pixel-wise absolute difference). We say the new image is a 3 if its distance to the archetypical 3 is lower than two the archetypical 7.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is a list comprehension? Create one now that selects odd numbers from a list and doubles them.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lists (arrays in other programming languages) are often generated using a for-loop. A list comprehension is a Pythonic way of condensing the creation of a list using a for-loop into a single expression. List comprehensions will also often include if clauses for filtering.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lst_in</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">lst_out</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">el</span> <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">lst_in</span> <span class="k">if</span> <span class="n">el</span><span class="o">%</span><span class="k">2</span>==1]
<span class="c1"># is equivalent to:</span>
<span class="n">lst_out</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">lst_in</span><span class="p">:</span>
   <span class="k">if</span> <span class="n">el</span><span class="o">%</span><span class="k">2</span>==1:
       <span class="n">lst_out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">el</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is a "rank-3 tensor"?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The rank of a tensor is the number of dimensions it has. An easy way to identify the rank is the number of indices you would need to reference a number within a tensor. A scalar can be represented as a tensor of rank 0 (no index), a vector can be represented as a tensor of rank 1 (one index, e.g., v[i]), a matrix can be represented as a tensor of rank 2 (two indices, e.g., a[i,j]), and a tensor of rank 3 is a cuboid or a “stack of matrices” (three indices, e.g., b[i,j,k]). In particular, the rank of a tensor is independent of its shape or dimensionality, e.g., a tensor of shape 2x2x2 and a tensor of shape 3x5x7 both have rank 3.
Note that the term “rank” has different meanings in the context of tensors and matrices (where it refers to the number of linearly independent column vectors).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is the difference between tensor rank and shape? How do you get the rank from the shape?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Rank is the number of axes or dimensions in a tensor; shape is the size of each axis of a tensor.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>How do you get the rank from the shape?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The length of a tensor’s shape is its rank.</p>
<p>So if we have the images of the 3 folder from the MINST_SAMPLE dataset in a tensor called stacked_threes and we find its shape like this.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stacked_threes</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>torch.Size([6131, 28, 28])</p>
<p>We just need to find its length to know its rank. This is done as follows.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">stacked_threes</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>3</p>
<p>You can also get a tensor’s rank directly with ndim .</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stacked_threes</span><span class="o">.</span><span class="n">ndim</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>3</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What are RMSE and L1 norm?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Root mean square error (RMSE), also called the L2 norm, and mean absolute difference (MAE), also called the L1 norm, are two commonly used methods of measuring “distance”. Simple differences do not work because some difference are positive and others are negative, canceling each other out. Therefore, a function that focuses on the magnitudes of the differences is needed to properly measure distances. The simplest would be to add the absolute values of the differences, which is what MAE is. RMSE takes the mean of the square (makes everything positive) and then takes the square root (undoes squaring).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As loops are very slow in Python, it is best to represent the operations as array operations rather than looping through individual elements. If this can be done, then using NumPy or PyTorch will be thousands of times faster, as they use underlying C code which is much faster than pure Python. Even better, PyTorch allows you to run operations on GPU, which will have significant speedup if there are parallel operations that can be done.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Create a 3×3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom-right four numbers.</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>tensor([[1., 2., 3.],
        [4., 5., 6.],
        [7., 8., 9.]])</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="p">;</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>tensor([[ 2.,  4.,  6.],
                     [ 8., 10., 12.],
                     [14., 16., 18.]])</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>tensor([[10., 12.],
                    [16., 18.]])</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is broadcasting?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Scientific/numerical Python packages like NumPy and PyTorch will often implement broadcasting that often makes code easier to write. In the case of PyTorch, tensors with smaller rank are expanded to have the same size as the larger rank tensor. In this way, operations can be performed between tensors with different rank.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Are metrics generally calculated using the training set, or the validation set? Why?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Metrics are generally calculated on a validation set. As the validation set is unseen data for the model, evaluating the metrics on the validation set is better in order to determine if there is any overfitting and how well the model might generalize if given similar data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is SGD?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>SGD, or stochastic gradient descent, is an optimization algorithm. Specifically, SGD is an algorithm that will update the parameters of a model in order to minimize a given loss function that was evaluated on the predictions and target. The key idea behind SGD (and many optimization algorithms, for that matter) is that the gradient of the loss function provides an indication of how that loss function changes in the parameter space, which we can use to determine how best to update the parameters in order to minimize the loss function. This is what SGD does.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Why does SGD use mini-batches?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need to calculate our loss function (and our gradient) on one or more data points. We cannot calculate on the whole datasets due to compute limitations and time constraints. If we iterated through each data point, however, the gradient will be unstable and imprecise, and is not suitable for training. As a compromise, we calculate the average loss for a small subset of the dataset at a time. This subset is called a mini-batch. Using mini-batches are also more computationally efficient than single items on a GPU.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What are the seven steps in SGD for machine learning?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Initialize the weights.</li>
<li>For each image, use these weights to predict whether it appears to be a 3 or a 7.</li>
<li>Based on these predictions, calculate how good the model is (its loss).</li>
<li>Calculate the gradient, which measures for each weight, how changing that weight would change the loss</li>
<li>Step (that is, change) all the weights based on that calculation.</li>
<li>Go back to the step 2, and repeat the process.</li>
<li>Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer).</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>How do we initialize the weights in a model?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Random weights work pretty well.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is "loss"?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The loss function will return a value based on the given predictions and targets, where lower values correspond to better model predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Why can't we always use a high learning rate?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The loss may “bounce” around (oscillate) or even diverge, as the optimizer is taking steps that are too large, and updating the parameters faster than it should be.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is a "gradient"?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The gradients tell us how much we have to change each weight to make our model better. It is essentially a measure of how the loss function changes with changes of the weights of the model (the derivative).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Do you need to know how to calculate gradients yourself?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Manual calculation of the gradients are not required, as deep learning libraries will automatically calculate the gradients for you. This feature is known as automatic differentiation. In PyTorch, if requires_grad=True, the gradients can be returned by calling the backward method: a.backward()</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Why can't we use accuracy as a loss function?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A loss function needs to change as the weights are being adjusted. Accuracy only changes if the predictions of the model change. So if there are slight changes to the model that, say, improves confidence in a prediction, but does not change the prediction, the accuracy will still not change. Therefore, the gradients will be zero everywhere except when the actual predictions change. The model therefore cannot learn from the gradients equal to zero, and the model’s weights will not update and will not train. A good loss function gives a slightly better loss when the model gives slightly better predictions. Slightly better predictions mean if the model is more confident about the correct prediction. For example, predicting 0.9 vs 0.7 for probability that a MNIST image is a 3 would be slightly better prediction. The loss function needs to reflect that.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Draw the sigmoid function. What is special about its shape?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Sigmoid.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sigmoid function is a smooth curve that squishes all values into values between 0 and 1. Most loss functions assume that the model is outputting some form of a probability or confidence level between 0 and 1 so we use a sigmoid function at the end of the model in order to do this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is the difference between a loss function and a metric?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The key difference is that metrics drive human understanding and losses drive automated learning. In order for loss to be useful for training, it needs to have a meaningful derivative. Many metrics, like accuracy are not like that. Metrics instead are the numbers that humans care about, that reflect the performance of the model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is the function to calculate new weights using a learning rate?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The optimizer step function</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What does the <code>DataLoader</code> class do?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The DataLoader class can take any Python collection and turn it into an iterator over many batches.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Write pseudocode showing the basic steps taken in each epoch for SGD.</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
   <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
   <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
   <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
   <span class="n">parameters</span> <span class="o">-=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Create a function that, if passed two arguments <code>[1,2,3,4]</code> and <code>'abcd'</code>, returns <code>[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]</code>. What is special about that output data structure?</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span> <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This data structure is useful for machine learning models when you need lists of tuples where each tuple would contain input data and a label.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What does <code>view</code> do in PyTorch?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It changes the shape of a Tensor without changing its contents.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What are the "bias" parameters in a neural network? Why do we need them?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Without the bias parameters, if the input is zero, the output will always be zero. Therefore, using bias parameters adds additional flexibility to the model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What does the <code>@</code> operator do in Python?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the matrix multiplication operator.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What does the <code>backward</code> method do?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This method returns the current gradients.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Why do we have to zero the gradients?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>PyTorch will add the gradients of a variable to any previously stored gradients. If the training loop function is called multiple times, without zeroing the gradients, the gradient of current loss would be added to the previously stored gradient value.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What information do we have to pass to <code>Learner</code>?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need to pass in the DataLoaders, the model, the optimization function, the loss function, and optionally any metrics to print.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Show Python or pseudocode for the basic steps of a training loop.</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
        <span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">*</span><span class="n">lr</span>
            <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is "ReLU"? Draw a plot of it for values from <code>-2</code> to <code>+2</code>.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ReLU just means “replace any negative numbers with zero”. It is a commonly used activation function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/im_sorry_dave/images/copied_from_nb/2020-12-10-Tears-In-Rain/Relu.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What is an "activation function"?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The activation function is another function that is part of the neural network, which has the purpose of providing non-linearity to the model. The idea is that without an activation function, we just have multiple linear functions of the form y=mx+b. However, a series of linear layers is equivalent to a single linear layer, so our model can only fit a line to the data. By introducing a non-linearity in between the linear layers, this is no longer true. Each layer is somewhat decoupled from the rest of the layers, and the model can now fit much more complex functions. In fact, it can be mathematically proven that such a model can solve any computable problem to an arbitrarily high accuracy, if the model is large enough with the correct weights. This is known as the universal approximation theorem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>What's the difference between <code>F.relu</code> and <code>nn.ReLU</code>?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>F.relu is a Python function for the relu activation function. On the other hand, nn.ReLU is a PyTorch module. This means that it is a Python class that can be called as a function in the same way as F.relu.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are practical performance benefits to using more than one nonlinearity. We can use a deeper model with less number of parameters, better performance, faster training, and less compute/memory requirements.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Further-Research">
<a class="anchor" href="#Further-Research" aria-hidden="true"><span class="octicon octicon-link"></span></a>Further Research<a class="anchor-link" href="#Further-Research"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>Create your own implementation of <code>Learner</code> from scratch, based on the training loop shown in this chapter.</li>
<li>Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s). This is a significant project and will take you quite a bit of time to complete! You'll need to do some of your own research to figure out how to overcome some obstacles you'll meet on the way.</li>
</ol>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="bailey-deep-learning/im_sorry_dave"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/im_sorry_dave/jupyter/2020/12/10/Tears-In-Rain.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/im_sorry_dave/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/im_sorry_dave/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/im_sorry_dave/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A deep learning journal of sorts</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/im_sorry_dave/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/im_sorry_dave/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
